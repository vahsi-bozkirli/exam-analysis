{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Algoritmalar",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khpbyL3BkE5R"
      },
      "source": [
        "Doğrusal Regresyonlar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hp49ZP2kynh"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxW9p8nAk2KL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUuyfyfcHEVm"
      },
      "source": [
        "## .................Regresyon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b_h5PzIZF2r"
      },
      "source": [
        "# Statsmodels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE_AHAoNdGSz"
      },
      "source": [
        "train test split çoklu doğrusal regresyonda kullanılır\n",
        "train test split kullanılmadığında direk x ve y kullanılabilir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdA5LGW1Y4ym"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x = \n",
        "x = sm.add_constant(x)\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "model = sm.OLS(y_train,x_train).fit()\n",
        "#model.summary()\n",
        "#model.predict(x_test)\n",
        "#model.fittedvalues\n",
        "mean_squared_error(y_test,model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-1yshRZdzD0"
      },
      "source": [
        "# Linear Regresyon "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "708niu_KbcQ_"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,\n",
        "                                                 random_state=42)\n",
        "model = LinearRegression().fit(x_train,y_train)\n",
        "#model.score(x_train,y_train)\n",
        "#model.predict(x_test)\n",
        "mean_squared_error(y_test,model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1O-Z0FEd9HX"
      },
      "source": [
        "# PCA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgTvA_6seHGF"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore') \n",
        "pca = PCA()\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "x_reduced_train = pca.fit_transform(scale(x_train))\n",
        "#np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)[0:5]\n",
        "model = LinearRegression().fit(x_reduced_train, y_train)\n",
        "\n",
        "x_reduced_test = pca2.fit_transform(scale(x_test))\n",
        "#model.predict(x_reduced_test)\n",
        "mean_squared_error(y_test,model.predict(x_reduced_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwOeiy3Ef5FG"
      },
      "source": [
        "# PLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmZgJgsOf8zp"
      },
      "source": [
        "from sklearn.cross_decomposition import PLSRegression, PLSSVD\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "pls_model = PLSRegression().fit(x_train, y_train)\n",
        "#pls_model.predict(x_test)\n",
        "r2_score(y_train,pls_model.predict(x_test))\n",
        "#mean_squared_error(y_test,pls_model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiQqjSaJhYk4"
      },
      "source": [
        "# Ridge Regresyon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18u2Pi0ohd7E"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "ridge_model = Ridge(alpha = 0.1).fit(x_train, y_train)\n",
        "#ridge_model.predict(x_test)\n",
        "mean_squared_error(y_test,ridge_model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NppHy2LZinjD"
      },
      "source": [
        "# Lasso Regresyon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzSJQB8-izNh"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "lasso_model = Lasso(alpha = 0.1).fit(x_train, y_train)\n",
        "#lasso_model.predict(x_test)\n",
        "mean_squared_error(y_test,lasso_model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqp2PqRKjcHb"
      },
      "source": [
        "# ElastikNet Regresyon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uO_meDdjgBz"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "enet_model = ElasticNet().fit(x_train, y_train)\n",
        "enet_model.predict(x_test)\n",
        "mean_squared_error(y_test,enet_model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFWgqNcgkY71"
      },
      "source": [
        "Doğrusal olmayan Regresyonlar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmjZjxlZkhYC"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E91rjzyIkgh1"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "knn_model = KNeighborsRegressor().fit(x_train, y_train)\n",
        "y_pred = knn_model.predict(x_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkUuXbnele44"
      },
      "source": [
        "# SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl-sSCTcloB4"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "svr_model = SVR(\"linear\").fit(x_train, y_train)\n",
        "y_pred = svr_model.predict(x_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf7spPC6mJZX"
      },
      "source": [
        "# Doğrusal olmayan SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UunBWlgAmUFA"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "svr_rbf = SVR(\"rbf\").fit(x_train, y_train)\n",
        "y_pred = svr_rbf.predict(x_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKZ3BbosnfDD"
      },
      "source": [
        "# Çok Katmanlı Algılayıcı"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCI9fN3HnkGq"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "mlp_model = MLPRegressor(hidden_layer_sizes = (100,20)).fit(x_train,y_train)\n",
        "y_pred = mlp_model.predict(x_test)\n",
        "mean_squared_error(y_test, y_pred)\n",
        "\n",
        "#mlp_model.n_layers_\n",
        "#mlp_model.hidden_layer_sizes\n",
        "#scaler = StandardScaler()\n",
        "#scaler.fit(x_train)\n",
        "#x_test_scaled = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwISf-NLowPV"
      },
      "source": [
        "# CART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXnRWwNLoyM9"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "cart_model = DecisionTreeRegressor(min_samples_split = 2)\n",
        "#cart_model.fit(x_train, y_train)\n",
        "y_pred =cart_model.predict(x_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "#!pip install skompiler\n",
        "#from skompiler import skompile\n",
        "\n",
        "#print(skompile(cart_model.predict).to('python/code'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmNZykYRqAiN"
      },
      "source": [
        "# Bagged Trees Regresyon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lufovuGjqFPm"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "bag_model = BaggingRegressor(bootstrap_features = True)\n",
        "bag_model.fit(x_train, y_train)\n",
        "y_pred = bag_model.predict(x_test)\n",
        "#bag_model.n_estimators\n",
        "#bag_model.estimators_\n",
        "#bag_model.estimators_samples_\n",
        "#bag_model.estimators_features_\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "iki_y_pred = bag_model.estimators_[1].fit(x_train, y_train).predict(x_test)\n",
        "np.sqrt(mean_squared_error(y_test, iki_y_pred))\n",
        "yedi_y_pred = bag_model.estimators_[4].fit(x_train, y_train).predict(x_test)\n",
        "np.sqrt(mean_squared_error(y_test, yedi_y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W215nwlsUiq_"
      },
      "source": [
        "# Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8epruz4qUmMa"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "rf_model = RandomForestRegressor(random_state = 42)\n",
        "rf_model.fit(x_train, y_train)\n",
        "y_pred = rf_model.predict(x_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e76FoNtDWVUZ"
      },
      "source": [
        "# Gradient Boosting Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRihNLIaWatp"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "\n",
        "gbm_model = GradientBoostingRegressor()\n",
        "gbm_model.fit(x_train, y_train)\n",
        "y_pred = gbm_model.predict(x_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re8eRlIvW2bR"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4my5K4LXEra"
      },
      "source": [
        "#!pip install xgboost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "DM_train = xgb.DMatrix(data = x_train, label = y_train)\n",
        "DM_test = xgb.DMatrix(data = x_test, label = y_test)\n",
        "xgb_model = XGBRegressor().fit(x_train, y_train)\n",
        "y_pred = xgb_model.predict(x_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErHLWevzX8c4"
      },
      "source": [
        "# Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTB661kcYTZW"
      },
      "source": [
        "#!pip install lightgbm\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "lgbm = LGBMRegressor()\n",
        "lgbm_model = lgbm.fit(x_train, y_train)\n",
        "y_pred = lgbm_model.predict(X_test, \n",
        "                            num_iteration = lgbm_model.best_iteration_)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "659yP2kYY0nq"
      },
      "source": [
        "# CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn09JUIzY8Ow"
      },
      "source": [
        "#!pip install catboost\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "catb = CatBoostRegressor()\n",
        "catb_model = catb.fit(x_train, y_train)\n",
        "y_pred = catb_model.predict(x_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--QAQOWaZeiq"
      },
      "source": [
        "## ...........Sınıflandırma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BigepTGlZsrF"
      },
      "source": [
        "# Lojistik Regresyon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUqFkOkuZkxC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "\n",
        "#statsmodels\n",
        "import statsmodels.api as sm\n",
        "loj = sm.Logit(y, x)\n",
        "loj_model= loj.fit()\n",
        "loj_model.summary()\n",
        "\n",
        "#scikit learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "loj = LogisticRegression(solver = \"liblinear\")\n",
        "loj_model = loj.fit(x,y)\n",
        "y_pred = loj_model.predict(x)\n",
        "cross_val_score(loj_model, x_test, y_test, cv = 10).mean()\n",
        "mean_squared_error(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB6ufnJBbeFC"
      },
      "source": [
        "# Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCYU3I7lblkl"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "nb = GaussianNB()\n",
        "nb_model = nb.fit(x_train, y_train)\n",
        "nb_model.predict_proba(x_test)\n",
        "y_pred = nb_model.predict(x_test)\n",
        "\n",
        "accuracy_score(y_test, y_pred)\n",
        "cross_val_score(nb_model, x_test, y_test, cv = 10).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2KQZxTr3fJA"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdhmwYrK3iz6"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "knn = KNeighborsClassifier()\n",
        "knn_model = knn.fit(x_train, y_train)\n",
        "y_pred = knn_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bl5EwGp55PR"
      },
      "source": [
        "# SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7_mo8m157lN"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "svm_model = SVC(kernel = \"linear\").fit(x_train, y_train)\n",
        "y_pred = svm_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtmctL-a6hrL"
      },
      "source": [
        "# RBF SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p34G1Hn6moz"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "svc_model = SVC(kernel = \"rbf\").fit(x_train, y_train)\n",
        "y_pred = svc_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj9kL1PS7BGP"
      },
      "source": [
        "# Yapay Sinir Ağları"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keogDnww7ETf"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "mlpc = MLPClassifier().fit(x_train, y_train)\n",
        "y_pred = mlpc.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)\n",
        "\"\"\"\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "X_train_scaled = scaler.transform(x_train)\n",
        "X_test_scaled = scaler.transform(x_test)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmdsJk-E7m8c"
      },
      "source": [
        "# CART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iN1aU607pj9"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "cart = DecisionTreeClassifier()\n",
        "cart_model = cart.fit(x_train, y_train)\n",
        "y_pred = cart_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRWC31JI8SDF"
      },
      "source": [
        "# Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2B83Uza8T8-"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "rf_model = RandomForestClassifier().fit(x_train, y_train)\n",
        "y_pred = rf_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqkrRjssEjwx"
      },
      "source": [
        "# Gradient Boosting Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpDlCGBpEljL"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "gbm_model = GradientBoostingClassifier().fit(x_train, y_train)\n",
        "y_pred = gbm_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-asXPFgFCZ3"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeZTh8FmFF5u"
      },
      "source": [
        "#!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "xgb_model = XGBClassifier().fit(x_train, y_train)\n",
        "y_pred = xgb_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2inOWI2FvyK"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynBXDrtJF1f6"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "lgbm_model = LGBMClassifier().fit(x_train, y_train)\n",
        "y_pred = lgbm_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XBTVbEGKkq"
      },
      "source": [
        "# CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaYspNfEGRxp"
      },
      "source": [
        "#!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "cat_model = CatBoostClassifier().fit(x_train, y_train)\n",
        "y_pred = cat_model.predict(x_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-tq0vnjHRAA"
      },
      "source": [
        "## ..............Gözetimsiz Öğrenme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnm-k5OzLVWy"
      },
      "source": [
        "KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycea1V5fHaRX"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "x =\n",
        "y = \n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
        "kmeans = KMeans(n_clusters = 4)\n",
        "k_fit = kmeans.fit(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}